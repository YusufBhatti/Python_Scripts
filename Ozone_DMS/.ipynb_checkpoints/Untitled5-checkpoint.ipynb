{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#Created on Mon Aug 23 16:00:04 2021\n",
    "\n",
    "#author: Alex Schud.\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import xarray as xr\n",
    "import time\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import cftime\n",
    "from pyesgf.search import SearchConnection\n",
    "\n",
    "####################################################################################################################\n",
    "#Run Parameters - Change based on machine/ what you want to download\n",
    "\n",
    "if (os.name=='nt'):\n",
    "    base_directory=Path('C:/Users/asc182/CMIP6/Cf')\n",
    "else:\n",
    "    base_directory=Path(\"/home/asc182/env/asc182/CMIP6/Rad\")\n",
    "\n",
    "variable_name='dmsos'\n",
    "exp_name='historical'\n",
    "Table_name='day'\n",
    "variant_name='r1i1p1f1'\n",
    "source_names=['UKESM1-0-LL']\n",
    "\n",
    "start_year='1940'\n",
    "end_year='2014'\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "year_list=range(int(start_year),int(end_year)+1)\n",
    "\n",
    "#connections to check\n",
    "Connection_List=['https://esgf-node.llnl.gov/esg-search','https://esgf-data.dkrz.de/esg-search','http://esgf-index1.ceda.ac.uk/esg-search']\n",
    "\n",
    "\n",
    "for server in Connection_List:\n",
    "    conn = SearchConnection(server, distrib=True)\n",
    "    \n",
    "    #search parameters\n",
    "    ctx = conn.new_context(\n",
    "    experiment_id=exp_name,\n",
    "    variable=variable_name,\n",
    "    table_id=Table_name,\n",
    "    source_id=source_names,\n",
    "    #variant_label=variant_name,  \n",
    "    data_node=['aims3.llnl.gov ','cmip.bcc.cma.cn','cmip.dess.tsinghua.edu.cn', 'cmip.fio.org.cn'\n",
    "               'crd-esgf-drc.ec.gc.ca', 'dist.nmlab.snu.ac.kr',\n",
    "               'dpesgf03.nccs.nasa.gov', 'esg-cccr.tropmet.res.in', 'esg-dn1.nsc.liu.se',\n",
    "               'esg-dn2.nsc.liu.se','esg.camscma.cn', 'esg.lasg.ac.cn', 'esg1.umr-cnrm.fr',\n",
    "               'esgdata.gfdl.noaa.gov', 'esgf-cnr.hpc.cineca.it','esgf-data.csc.fi','esgf-data.ucar.edu',\n",
    "               'esgf-data2.diasjp.net', 'esgf-data2.llnl.gov', 'noresg.nird.sigma2.no'\n",
    "               'esgf-data3.ceda.ac.uk', 'esgf-nimscmip6.apcc21.org', 'esgf-node2.cmcc.it',\n",
    "               'esgf.bsc.es', 'esgf.ichec.ie', 'esgf.nci.org.au', 'esgf.rcec.sinica.edu.tw',\n",
    "               'esgf3.dkrz.de', 'polaris.pknu.ac.kr', 'vesg.ipsl.upmc.fr'])\n",
    "    \n",
    "    for result in ctx.search():\n",
    "        files = result.file_context().search()\n",
    "        text_ind=result.dataset_id.find(\".v\")\n",
    "    \n",
    "        tmp_string=result.dataset_id[0:text_ind]\n",
    "    \n",
    "        directory_string=Path(base_directory / tmp_string) \n",
    "        if(os.path.isdir(directory_string)):\n",
    "            print('directory already created')\n",
    "        else:\n",
    "            os.mkdir(directory_string)\n",
    "    \n",
    "        string_list=[]    \n",
    "        file_list=[]\n",
    "        for f in files:\n",
    "            string_list.append(f.opendap_url)\n",
    "            file_list.append(f.filename)\n",
    "            #print(f.opendap_url)\n",
    "    \n",
    "        count=0\n",
    "        for tmp_string in string_list:\n",
    "            print()\n",
    "            print(tmp_string)\n",
    "            if not(tmp_string==None):\n",
    "                file_split=tmp_string.split('/')\n",
    "                second_split=file_split[-1].split('_')\n",
    "                first_year=int(second_split[-1][0:4])\n",
    "                hyphen=second_split[-1].index('-')\n",
    "                second_year=int(second_split[-1][hyphen+1:hyphen+5])\n",
    "\n",
    "                \n",
    "                if first_year > int(end_year) or second_year < int(start_year): \n",
    "                    print('Outside time period')\n",
    "                else:\n",
    "                    try:\n",
    "                        if variable_name=='clisccp':\n",
    "                            dataset = xr.open_dataset(tmp_string,chunks={'time': 1},engine='pydap', use_cftime=True,decode_times=True)\n",
    "                        else:\n",
    "                            dataset = xr.open_dataset(tmp_string,engine='pydap', use_cftime=True,decode_times=True)                        #dataset = xr.open_dataset(tmp_string,chunks=10000,engine='pydap', use_cftime=False,decode_times=False)\n",
    "                        attributes=dataset.attrs\n",
    "                        ##iterate through the years and save yearly\n",
    "                        for tmp_year in year_list:\n",
    "                            tmp_start_time=str(tmp_year)+'-01-01'\n",
    "                            if type(dataset['time'].data[0])==cftime._cftime.Datetime360Day:\n",
    "                                tmp_end_time=str(tmp_year)+'-12-30'\n",
    "                            else:\n",
    "                                tmp_end_time=str(tmp_year)+'-12-31'\n",
    "                            \n",
    "                            variable_xarray=dataset[variable_name].sel(time=slice(tmp_start_time,tmp_end_time))\n",
    "                            variable_xarray.attrs=attributes\n",
    "                            \n",
    "                            if not(variable_xarray.size==0):\n",
    "                                start_period=variable_xarray['time'].data[0]\n",
    "                                end_period=variable_xarray['time'].data[-1]\n",
    "                                \n",
    "                                tmp_start_string='days since ' +str(tmp_year)+'-01-01'\n",
    "                                \n",
    "                                try:\n",
    "                                    start_index=cftime.date2num(start_period,tmp_start_string)\n",
    "                                except:\n",
    "                                    start_index=cftime.date2num(start_period,tmp_start_string,calendar='noleap')\n",
    "                                    \n",
    "                                try:\n",
    "                                    end_index=cftime.date2num(end_period,tmp_start_string)\n",
    "                                except:\n",
    "                                    end_index=cftime.date2num(end_period,tmp_start_string,calendar='noleap')\n",
    "                                          \n",
    "                                \n",
    "                                tmp_year_val=tmp_year\n",
    "                                tmp_starting_day=int(np.ceil(start_index))\n",
    "                                tmp_ending_day=int(np.ceil(end_index))\n",
    "                                \n",
    "                                tmp_file_name=second_split[0]+'_'+str(tmp_year_val)+'_'+str(tmp_starting_day)+'-'+str(tmp_ending_day)+'.nc'\n",
    "                                tmp_full_name=Path(directory_string / tmp_file_name)\n",
    "\n",
    "                                if os.path.isfile(tmp_full_name) and os.path.getsize(tmp_full_name)>1000000:\n",
    "                                    print('File Already downloaded')\n",
    "                                else:\n",
    "                                    variable_xarray.to_netcdf(tmp_full_name)#,'w',format='NETCDF4_CLASSIC')\n",
    "                                    variable_xarray.close\n",
    "                                    print(tmp_file_name)\n",
    "                        \n",
    "                        \n",
    "                        dataset.close\n",
    "                        #variable_xarray.close\n",
    "                        #variable_dataset.close\n",
    "                        time.sleep(0.22)\n",
    "        \n",
    "                        count+=1\n",
    "                    except(FileNotFoundError):\n",
    "                        print('File not found')\n",
    "                    except:\n",
    "                        print('Exception in download')\n",
    "                \n",
    "                        time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
