{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "#from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "model = 'UKESM1'\n",
    "scenarios = ['Historic']\n",
    "ensembles = ['r1i1p1f2','r2i1p1f2','r3i1p1f2', 'r4i1p1f2','r8i1p1f2','r9i1p1f2','r10i1p1f2', 'r11i1p1f2', 'r12i1p1f2', 'r16i1p1f2','r17i1p1f2','r18i1p1f2','r19i1p1f2']\n",
    "\n",
    "DATAPATH = '/nesi/project/niwa02757/ybh10/CMIP6/{}/'.format(model)\n",
    "fileList = []\n",
    "for scenario in scenarios:\n",
    "    for ensemble in ensembles:\n",
    "        ensemble_list = []\n",
    "        files = [f for f in os.listdir(DATAPATH+scenario+'/Ozone_loss') if ensemble in f]\n",
    "        for f in files:\n",
    "            ensemble_list.append(DATAPATH + scenario + '/Ozone_loss/' + f)\n",
    "        fileList.append(ensemble_list)\n",
    "\n",
    "fileList.sort()\n",
    "print(fileList)\n",
    "\n",
    "def preprocess(ds):\n",
    "    data = ds\n",
    "    data = data.groupby('time.season').mean(dim='time').load()\n",
    "    return data\n",
    "\n",
    "test1 = []\n",
    "test2 = []\n",
    "for i in range(0,13):\n",
    "    with xr.open_mfdataset(fileList[i], combine='by_coords', preprocess=preprocess, parallel=False) as file:\n",
    "        test1.append(file['uas'].sel(lat = slice(-90, -60), ))\n",
    "  #      test2.append(file['uas'].sel(lat = slice(-90, -60), year = slice(2090, 2100)).mean('lon').mean('year'))\n",
    "        print(fileList[i])\n",
    "\n",
    "stacked_ensembles1 = np.stack((test1[0], test1[1], test1[2], test1[3], test1[4], test1[5], test1[6], test1[7], test1[8], test1[9]), axis = 1)\n",
    "#stacked_ensembles2 = np.stack((test2[0], test2[1], test2[2], test2[3], test2[4], test2[5], test2[6], test2[7], test2[8], test2[9]), axis = 1)\n",
    "\n",
    "\n",
    "median1 = np.percentile(stacked_ensembles1, 50, axis = 1)\n",
    "median2 = np.percentile(stacked_ensembles2, 50, axis = 1)\n",
    "\n",
    "    \n",
    "plt.plot(file['lat'].sel(lat = slice(-90, 0)).values, (median2 - median1)/7, label = 'Change per decade')\n",
    "plt.title('GISS-E2-1-G (with interactive chemistry)')\n",
    "plt.xlabel('Latitude')\n",
    "plt.ylabel('uas trend (m/s/decade)')\n",
    "plt.legend()\n",
    "np.save('GISS_trend_chem',(median2 - median1)/7)\n",
    "np.save('GISS-E2-1-G_latitude',file['lat'].sel(lat = slice(-90, 0)).values)\n",
    "\n",
    "def seasonalise(group):\n",
    "    seasonal = group.groupby('time.season').mean('time')\n",
    "  #  seasonal = seasonal.sel(season='DJF')\n",
    "    return(seasonal)\n",
    "\n",
    "def preprocess(ds):\n",
    "    data = ds\n",
    "        \n",
    "    dy = data.groupby('time.year').map(seasonalise).load()  \n",
    "     \n",
    "    return dy\n",
    "# with xr.open_mfdataset(fileList[i], combine='by_coords', preprocess=preprocess, parallel=False) as file:\n",
    "DMS_ppt=((29/62.13)*1e12)\n",
    "ODMS_ppm=(((18/62.13)*1e9))\n",
    "SO2_ppt=((29/64.06)*1e12)\n",
    "O3_ppm=((29/48)*1e6)\n",
    "test3 = []\n",
    "test4 = []\n",
    "for i in range(0,13):\n",
    "    with xr.open_mfdataset(fileList[i], combine='by_coords', preprocess=preprocess, parallel=False) as file:\n",
    "    #    weights = np.cos(np.deg2rad(file['lat']).sel(lat = slice(-65,-55)))\n",
    "        averaged_uas_start = (file['toz'].sel(lat = slice (-90, -60)))\n",
    " #       averaged_uas_end = (file['uas'].sel(year = slice(2090,2100), lat = slice (-65, -55))*weights).sum('lat').mean('lon').mean('year')/np.sum(weights)\n",
    "        test3.append(averaged_uas_start)\n",
    "    print(np.shape(test3))\n",
    "  #      test4.append(averaged_uas_end)\n",
    "median3 = np.median(test3)\n",
    "median4 = np.median(test4)\n",
    "np.save('GISS-E2-1-G_averaged_uas', (median4-median3)/7)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "#from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "model = 'UKESM1'\n",
    "scenarios = ['Historic']\n",
    "ensembles = ['r1i1p1f2','r2i1p1f2','r3i1p1f2', 'r4i1p1f2','r8i1p1f2','r9i1p1f2','r10i1p1f2', 'r11i1p1f2', 'r12i1p1f2', 'r16i1p1f2','r17i1p1f2','r18i1p1f2','r19i1p1f2']\n",
    "\n",
    "DATAPATH = '/nesi/project/niwa02757/ybh10/CMIP6/{}/'.format(model)\n",
    "fileList = []\n",
    "for scenario in scenarios:\n",
    "    for ensemble in ensembles:\n",
    "        ensemble_list = []\n",
    "        files = [f for f in os.listdir(DATAPATH+scenario+'/Wind') if ensemble in f]\n",
    "        for f in files:\n",
    "            ensemble_list.append(DATAPATH + scenario + '/Wind/' + f)\n",
    "        fileList.append(ensemble_list)\n",
    "\n",
    "fileList.sort()\n",
    "print(fileList)\n",
    "\n",
    "def preprocess(ds):\n",
    "    data = ds\n",
    "    data = data.groupby('time.season').mean('time').load()\n",
    "    return data\n",
    "\n",
    "test1 = []\n",
    "test2 = []\n",
    "for i in range(0,13):\n",
    "    with xr.open_mfdataset(fileList[i], combine='by_coords', preprocess=preprocess, parallel=False) as file:\n",
    "        test1.append(file['uas'].sel(lat = slice(-90, -60), year = slice(1850, 2014)))\n",
    "        print(fileList[i])\n",
    "  #      test2.append(file['uas'].sel(lat = slice(-90, -60), year = slice(2090, 2100)).mean('lon').mean('year'))\n",
    "        \n",
    "stacked_ensembles1 = np.stack((test1[0], test1[1], test1[2], test1[3], test1[4], test1[5], test1[6], test1[7], test1[8], test1[9]), axis = 1)\n",
    "#stacked_ensembles2 = np.stack((test2[0], test2[1], test2[2], test2[3], test2[4], test2[5], test2[6], test2[7], test2[8], test2[9]), axis = 1)\n",
    "\n",
    "\n",
    "median1 = np.percentile(stacked_ensembles1, 50, axis = 1)\n",
    "median2 = np.percentile(stacked_ensembles2, 50, axis = 1)\n",
    "\n",
    "    \n",
    "plt.plot(file['lat'].sel(lat = slice(-90, 0)).values, (median2 - median1)/7, label = 'Change per decade')\n",
    "plt.title('GISS-E2-1-G (with interactive chemistry)')\n",
    "plt.xlabel('Latitude')\n",
    "plt.ylabel('uas trend (m/s/decade)')\n",
    "plt.legend()\n",
    "np.save('GISS_trend_chem',(median2 - median1)/7)\n",
    "np.save('GISS-E2-1-G_latitude',file['lat'].sel(lat = slice(-90, 0)).values)\n",
    "\n",
    "def seasonalise(group):\n",
    "    seasonal = group.groupby('time.season').mean('time')\n",
    "    seasonal = seasonal.sel(season='DJF')\n",
    "    return(seasonal)\n",
    "\n",
    "def preprocess(ds):\n",
    "    data = ds\n",
    "        \n",
    "    dy = data.groupby('time.year').map(seasonalise).load()  \n",
    "     \n",
    "    return dy\n",
    "\n",
    "\n",
    "test3 = []\n",
    "test4 = []\n",
    "for i in range(0,10):\n",
    "    with xr.open_mfdataset(fileList[i], combine='by_coords', preprocess=preprocess, parallel=False) as file:\n",
    "        \n",
    "        weights = np.cos(np.deg2rad(file['lat']).sel(lat = slice(-65,-55)))\n",
    "        averaged_uas_start = (file['uas'].sel(year = slice(2020,2030), lat = slice (-65, -55))*weights).sum('lat').mean('lon').mean('year')/np.sum(weights)\n",
    "        averaged_uas_end = (file['uas'].sel(year = slice(2090,2100), lat = slice (-65, -55))*weights).sum('lat').mean('lon').mean('year')/np.sum(weights)\n",
    "        test3.append(averaged_uas_start)\n",
    "        test4.append(averaged_uas_end)\n",
    "median3 = np.median(test3)\n",
    "median4 = np.median(test4)\n",
    "np.save('GISS-E2-1-G_averaged_uas', (median4-median3)/7)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n",
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 165, 4, 30, 360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n",
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 165, 4, 30, 360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n",
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 165, 4, 30, 360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n",
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 165, 4, 30, 360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n",
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 165, 4, 30, 360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n",
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 165, 4, 30, 360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n",
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 165, 4, 30, 360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n",
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 165, 4, 30, 360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n",
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 165, 4, 30, 360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n",
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 165, 4, 30, 360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n",
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 165, 4, 30, 360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n",
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 165, 4, 30, 360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n",
      "/nesi/project/niwa02757/ybh10/miniconda3/envs/master/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 165, 4, 30, 360)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "#from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "def seasonalise(group):\n",
    "    seasonal = group.groupby('time.season').mean('time')\n",
    "   # seasonal = seasonal.sel(season='DJF')\n",
    "    return(seasonal)\n",
    "\n",
    "def preprocess(ds):\n",
    "    data = ds\n",
    "        \n",
    "    dy = data.groupby('time.year').map(seasonalise).load()  \n",
    "     \n",
    "    return dy\n",
    "\n",
    "model = 'UKESM1'\n",
    "scenarios = ['Historic']\n",
    "ensembles = ['r1i1p1f2','r2i1p1f2','r3i1p1f2', 'r4i1p1f2','r8i1p1f2','r9i1p1f2','r10i1p1f2', 'r11i1p1f2', 'r12i1p1f2', 'r16i1p1f2','r17i1p1f2','r18i1p1f2','r19i1p1f2']\n",
    "DATAPATH = '/nesi/project/niwa02757/ybh10/CMIP6/{}/'.format(model)\n",
    "\n",
    "fileList = []\n",
    "for scenario in scenarios:\n",
    "    for ensemble in ensembles:\n",
    "        ensemble_list = []\n",
    "        files = [f for f in os.listdir(DATAPATH+scenario+'/Ozone_loss') if ensemble in f]\n",
    "        for f in files:\n",
    "            ensemble_list.append(DATAPATH + scenario + '/Ozone_loss/' + f)\n",
    "        fileList.append(ensemble_list)\n",
    "fileList.sort()\n",
    "\n",
    "aa=np.empty((165,4,144,192)); a[:]=np.nan\n",
    "\n",
    "#averaged_ensemble_SO[i,x]=np.corrcoef(DMS_50_mean[:,i,x],Ozone_mean_2d[:,i])[1,0]\n",
    "\n",
    "average=[]\n",
    "average_global=[]\n",
    "average_SO=[]\n",
    "averaged_ensemble_SO\n",
    "for i in range(0,13):\n",
    "    with xr.open_mfdataset(fileList[i], combine='by_coords', preprocess=preprocess, parallel=False) as file:\n",
    " #       averaged_ensemble = (file['toz'].sel(lat = slice (-90, -60)))\n",
    " #       averaged_ensemble_global = (file['toz'])\n",
    "        averaged_ensemble_SO[i] = (file['toz'].sel(lat = slice (-65, -50)))\n",
    "\n",
    "\n",
    "     #   average.append(averaged_ensemble)\n",
    "  #      average_global.append(averaged_ensemble_global)\n",
    "       # average_SO.append(averaged_ensemble_SO)\n",
    "\n",
    " #   print(np.shape(average))\n",
    "\n",
    "np.save('/home/ybh10/CMIP6/UKESM1/Historic/Numpy_Array/Ozone_Region/50_65/Ocean_DMS_50_65S.npy',average_SO)\n",
    "#np.save('/home/ybh10/CMIP6/UKESM1/Historic/Numpy_Array/Ozone_Region/Ensemble_mean/Ocean_DMS_60_90S.npy',average)\n",
    "#np.save('/home/ybh10/CMIP6/UKESM1/Historic/Numpy_Array/Global/Ensemble_mean/Ozone_Column_Global.npy',average_global)############\n",
    "\n",
    "DATAPATH = '/nesi/project/niwa02757/ybh10/CMIP6/{}/'.format(model)\n",
    "fileList = []\n",
    "for scenario in scenarios:\n",
    "    for ensemble in ensembles:\n",
    "        ensemble_list = []\n",
    "        files = [f for f in os.listdir(DATAPATH+scenario+'/DMS') if ensemble in f]\n",
    "        for f in files:\n",
    "            ensemble_list.append(DATAPATH + scenario + '/DMS/' + f)\n",
    "        fileList.append(ensemble_list)\n",
    "fileList.sort()\n",
    "\n",
    "average=[]\n",
    "average_global=[]\n",
    "average_SO=[]\n",
    "for i in range(0,13):\n",
    "    with xr.open_mfdataset(fileList[i], combine='by_coords', preprocess=preprocess, parallel=False) as file:\n",
    "#        averaged_ensemble = (file['dms'][:,:,0].sel(lat = slice (-90, -60)))\n",
    " #       averaged_ensemble_global = (file['dms'][:,:,0])\n",
    "        averaged_ensemble_SO = (file['dms'][:,:,0].sel(lat = slice (-65, -50)))\n",
    "\n",
    "#        average.append(averaged_ensemble)\n",
    " #       average_global.append(averaged_ensemble_global)\n",
    "        average_SO.append(averaged_ensemble_SO)\n",
    "\n",
    "\n",
    "\n",
    "    print(np.shape(average))\n",
    "np.save('/home/ybh10/CMIP6/UKESM1/Historic/Numpy_Array/Ozone_Region/50_65/DMS_50_65S.npy',average_SO)\n",
    "#np.save('/home/ybh10/CMIP6/UKESM1/Historic/Numpy_Array/Ozone_Region/Ensemble_mean/DMS_60_90S.npy',average)\n",
    "#np.save('/home/ybh10/CMIP6/UKESM1/Historic/Numpy_Array/Global/Ensemble_mean/DMS_Global.npy',average_global)############\n",
    "gc.collect()\n",
    "############\n",
    "DATAPATH = '/nesi/project/niwa02757/ybh10/CMIP6/{}/'.format(model)\n",
    "fileList = []\n",
    "for scenario in scenarios:\n",
    "    for ensemble in ensembles:\n",
    "        ensemble_list = []\n",
    "        files = [f for f in os.listdir(DATAPATH+scenario+'/SO2') if ensemble in f]\n",
    "        for f in files:\n",
    "            ensemble_list.append(DATAPATH + scenario + '/SO2/' + f)\n",
    "        fileList.append(ensemble_list)\n",
    "fileList.sort()\n",
    "\n",
    "average=[]\n",
    "average_global=[]\n",
    "average_SO=[]\n",
    "for i in range(0,13):\n",
    "    with xr.open_mfdataset(fileList[i], combine='by_coords', preprocess=preprocess, parallel=False) as file:\n",
    "#        averaged_ensemble = (file['so2'][:,:,0].sel(lat = slice (-90, -60)))\n",
    "     #   averaged_ensemble_global = (file['so2'][:,:,0])\n",
    "        averaged_ensemble_SO = (file['so2'][:,:,0].sel(lat = slice (-65, -50)))\n",
    "\n",
    "        #     average.append(averaged_ensemble)\n",
    " #       average_global.append(averaged_ensemble_global)\n",
    "        average_SO.append(averaged_ensemble_SO)\n",
    "\n",
    "\n",
    "    print(np.shape(average_global))\n",
    "np.save('/home/ybh10/CMIP6/UKESM1/Historic/Numpy_Array/Ozone_Region/50_65/SO2_50_65S.npy',average_SO)\n",
    "#np.save('/home/ybh10/CMIP6/UKESM1/Historic/Numpy_Array/Ozone_Region/Ensemble_mean/SO2_60_90S.npy',average)\n",
    "#np.save('/home/ybh10/CMIP6/UKESM1/Historic/Numpy_Array/Global/Ensemble_mean/SO2_Global.npy',average_global)\n",
    "#############\n",
    "DATAPATH = '/nesi/project/niwa02757/ybh10/CMIP6/{}/'.format(model)\n",
    "fileList = []\n",
    "for scenario in scenarios:\n",
    "    for ensemble in ensembles:\n",
    "        ensemble_list = []\n",
    "        files = [f for f in os.listdir(DATAPATH+scenario+'/Ocean_DMS') if ensemble in f]\n",
    "        for f in files:\n",
    "            ensemble_list.append(DATAPATH + scenario + '/Ocean_DMS/' + f)\n",
    "        fileList.append(ensemble_list)\n",
    "fileList.sort()\n",
    "\n",
    "average=[]\n",
    "average_global=[]\n",
    "average_SO=[]\n",
    "\n",
    "for i in range(0,13):\n",
    "    with xr.open_mfdataset(fileList[i], combine='by_coords', preprocess=preprocess, parallel=False) as file:\n",
    "   #     averaged_ensemble = (file['dmsos'].sel(j = slice (0, 94)))\n",
    "  #      averaged_ensemble_global = (file['dmsos'])\n",
    "        averaged_ensemble_SO = (file['dmsos'].sel(j = slice (83, 112)))\n",
    "        \n",
    " #       average.append(averaged_ensemble)\n",
    " #       average_global.append(averaged_ensemble_global)\n",
    "        average_SO.append(averaged_ensemble_SO)\n",
    "\n",
    "\n",
    "    \n",
    "    print(np.shape(average_SO))\n",
    "np.save('/home/ybh10/CMIP6/UKESM1/Historic/Numpy_Array/Ozone_Region/50_65/Ocean_DMS_50_65S.npy',average_SO)\n",
    "\n",
    "#np.save('/home/ybh10/CMIP6/UKESM1/Historic/Numpy_Array/Ozone_Region/Ensemble_mean/Ocean_DMS_60_90S.npy',average)\n",
    "#np.save('/home/ybh10/CMIP6/UKESM1/Historic/Numpy_Array/Global/Ensemble_mean/Ocean_DMS_Global.npy',average_global)\n",
    "\n",
    "##############\n",
    "DATAPATH = '/nesi/project/niwa02757/ybh10/CMIP6/{}/'.format(model)\n",
    "fileList = []\n",
    "for scenario in scenarios:\n",
    "    for ensemble in ensembles:\n",
    "        ensemble_list = []\n",
    "        files = [f for f in os.listdir(DATAPATH+scenario+'/AOD') if ensemble in f]\n",
    "        for f in files:\n",
    "            ensemble_list.append(DATAPATH + scenario + '/AOD/' + f)\n",
    "        fileList.append(ensemble_list)\n",
    "fileList.sort()\n",
    "\n",
    "average=[]\n",
    "average_global=[]\n",
    "average_SO=[]\n",
    "\n",
    "for i in range(0,13):\n",
    "    with xr.open_mfdataset(fileList[i], combine='by_coords', preprocess=preprocess, parallel=False) as file:\n",
    "  #      averaged_ensemble = (file['od550aer'].sel(lat = slice (-90, -60)))\n",
    " #       averaged_ensemble_global = (file['od550aer'])\n",
    "        averaged_ensemble_SO = (file['od550aer'].sel(lat = slice (-65, -50)))\n",
    "        \n",
    "  #      average.append(averaged_ensemble)\n",
    "  #      average_global.append(averaged_ensemble_global)     \n",
    "        average_SO.append(averaged_ensemble_SO)\n",
    "\n",
    "    print(np.shape(average))\n",
    "\n",
    "np.save('/home/ybh10/CMIP6/UKESM1/Historic/Numpy_Array/Ozone_Region/50_65/AOD_50_65S.npy',average_SO)\n",
    "#np.save('/home/ybh10/CMIP6/UKESM1/Historic/Numpy_Array/Ozone_Region/Ensemble_mean/AOD_60_90S.npy',average)\n",
    "#np.save('/home/ybh10/CMIP6/UKESM1/Historic/Numpy_Array/Global/Ensemble_mean/AOD_Global.npy',average_global)\n",
    "\n",
    "##############\n",
    "DATAPATH = '/nesi/project/niwa02757/ybh10/CMIP6/{}/'.format(model)\n",
    "fileList = []\n",
    "for scenario in scenarios:\n",
    "    for ensemble in ensembles:\n",
    "        ensemble_list = []\n",
    "        files = [f for f in os.listdir(DATAPATH+scenario+'/Wind') if ensemble in f]\n",
    "        for f in files:\n",
    "            ensemble_list.append(DATAPATH + scenario + '/Wind/' + f)\n",
    "        fileList.append(ensemble_list)\n",
    "fileList.sort()\n",
    "\n",
    "average=[]\n",
    "average_global=[]\n",
    "average_SO=[]\n",
    "for i in range(0,13):\n",
    "    with xr.open_mfdataset(fileList[i], combine='by_coords', preprocess=preprocess, parallel=False) as file:\n",
    "   #     averaged_ensemble = (file['uas'].sel(lat = slice (-90, -60)))\n",
    "   #     averaged_ensemble_global = (file['uas'])\n",
    "        averaged_ensemble_SO = (file['uas'].sel(lat = slice (-65, -50)))\n",
    "        \n",
    " #       average.append(averaged_ensemble)\n",
    " #       average_global.append(averaged_ensemble_global)\n",
    "        average_SO.append(averaged_ensemble_SO)\n",
    "        \n",
    "    print(np.shape(average))\n",
    "np.save('/home/ybh10/CMIP6/UKESM1/Historic/Numpy_Array/Ozone_Region/50_65/Wind_50_65S.npy',average_SO)\n",
    "#np.save('/home/ybh10/CMIP6/UKESM1/Historic/Numpy_Array/Ozone_Region/Ensemble_mean/Wind_60_90S.npy',average)\n",
    "#np.save('/home/ybh10/CMIP6/UKESM1/Historic/Numpy_Array/Global/Ensemble_mean/Wind_Global.npy',average_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
